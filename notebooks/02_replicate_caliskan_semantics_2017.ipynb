{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replication of Caliskan et al. \"Semantics derived automatically from language corpora contain human-like biases\"\n",
    "\n",
    "| Author | Last update |\n",
    "|:------ |:----------- |\n",
    "| Hauke Licht (https://github.com/haukelicht) | 2023-09-26 |\n",
    "\n",
    "In their often-cited *Science* [publication](https://www.science.org/doi/10.1126/science.aal4230) \"Semantics derived automatically from language corpora contain human-like biases,\" Caliskan, Bryson, and Narayanan propose a method for quantifying the biases captured in word embedding models.\n",
    "\n",
    "In their abstract, they write:\n",
    "\n",
    "> ... we show that applying machine learning to ordinary human language results in human-like semantic biases. \n",
    "> We replicate aspectrum of known biases, as measured by the *Implicit Association Test*, using a widely used, purely statistical machine-learning model trained on a standard corpus of text from the Web.\n",
    "> Our results indicate that text corpora contain recoverable and accurate imprints of our historic biases, whether morally neutral as towards insects or flowers, problematic as towards race or gender, or even simply veridical, reflecting the status quo distribution of gender with respect to careers or first names.\n",
    "\n",
    "\n",
    "## Replication: goals and approach\n",
    "\n",
    "In this notebook, we replicate their analyses.\n",
    "Out goal is to see if we find the same patterns they describe in their publication.\n",
    "We do this using their original word lists but a different word embedding model.\n",
    "\n",
    "Our replication will focus on their **WEAT** metric â€“ the *Word Embedding Association Test*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Before we can get going, let's set up our notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import gensim\n",
    "import gensim.downloader as api\n",
    "\n",
    "data_path =  os.path.join('..', 'data', 'replications', 'caliskan_semantics_2017')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Note:_** \n",
    "We'll work with data collected by Github user `chadaeun` for his 'weat_replication' project.\n",
    "The data relavant data is available at https://github.com/chadaeun/weat_replication/blob/master/weat/weat.json and has already been downloaded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The WEAT\n",
    "\n",
    "Let\n",
    "\n",
    "- $X$ and $Y$ be two sets of **_target words_** of equal size (to be tested for association), and\n",
    "- $A$ and $B$ the two sets of **_attribute words_** (indciating conceptual opposites).\n",
    "\n",
    "#### Example\n",
    "\n",
    "- The *target words* could be occupations ('programmer', 'engineer', 'scientist'; and 'nurse', 'teacher', 'librarian').\n",
    "- The two sets of *attribute words* could be ('man', 'male') and ('woman', 'female').\n",
    "\n",
    "#### Formula\n",
    "\n",
    "The test statistic $s$ of the word-embedding association test (WEAT) is defined as \n",
    "\n",
    "$$\n",
    "s(X, Y, A, B)=\\sum_{x \\in X} s(x, A, B)-\\sum_{y \\in Y} s(y, A, B)\n",
    "$$\n",
    "\n",
    "where \n",
    "\n",
    "$$\n",
    "s(w, A, B) =\\operatorname{mean}_{a \\in A} \\cos (\\vec{w}, \\vec{a})-\\operatorname{mean}_{b \\in B} \\cos (\\vec{w}, \\vec{b})\n",
    "$$\n",
    "\n",
    "measures the association of $w$ with the attribute, and\n",
    "$s(X,Y,A,B)$ measures the differential association of the two sets of target words $A$ and $B$ with the attribute.\n",
    "\n",
    "The **null hypothesis** is that there is no difference between the two sets of target words in terms of their relative similarity to the two sets of attribute words, i.e., $\\text{H}_0: s = 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example with code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the lists of target and attribute words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first load the dictionary of wordlists Caliskan et al. (2017) used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = os.path.join(data_path, 'wordlists.json')\n",
    "wordlists = json.load(open(fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Careers_Female_Male',\n",
       " 'EuropeanAmerican_AfricanAmerican_Pleasant_Unpleasant',\n",
       " 'EuropeanAmerican_AfricanAmerican_Pleasant_Unpleasant_2',\n",
       " 'Flowers_Insects_Pleasant_Unpleasant',\n",
       " 'Male_Female_Career_Family',\n",
       " 'Math_Arts_Male_Female',\n",
       " 'MusicalInstruments_Weapons_Pleasant_Unpleasant',\n",
       " 'Names_Female_Male',\n",
       " 'Science_Arts_Male_Female']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(wordlists.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with the example of the WEAT for science and art attributes with target words representing the concepts \"male\" and \"female\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['A_key', 'Arts words', 'B_key', 'Female attributes', 'Male attributes', 'Science words', 'X_key', 'Y_key', 'attributes', 'method', 'targets'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict = wordlists['Science_Arts_Male_Female']\n",
    "data_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Note:_** Each top-level dictionary element contains a dictionary with the same set of keys."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to use the following attribute words list for A and B:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: ['brother', 'father', 'uncle', 'grandfather', 'son', 'he', 'his', 'him']\n",
      "B: ['sister', 'mother', 'aunt', 'grandmother', 'daughter', 'she', 'hers', 'her']\n"
     ]
    }
   ],
   "source": [
    "A_key = data_dict['A_key']\n",
    "print('A:', data_dict[A_key])\n",
    "B_key = data_dict['B_key']\n",
    "print('B:', data_dict[B_key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And for the target words X and Y, we use the following word lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: ['science', 'technology', 'physics', 'chemistry', 'einstein', 'nasa', 'experiment', 'astronomy']\n",
      "Y: ['poetry', 'art', 'shakespeare', 'dance', 'literature', 'novel', 'symphony', 'drama']\n"
     ]
    }
   ],
   "source": [
    "X_key = data_dict['X_key']\n",
    "print('X:', data_dict[X_key])\n",
    "Y_key = data_dict['Y_key']\n",
    "print('Y:', data_dict[Y_key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a pre-trained embedding model and get target and attribute words' embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to get these words embeddings.\n",
    "We'll use a word2vec model available with `gensim` and use a helper function to extract word vectors from it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import numpy as np\n",
    "\n",
    "model = api.load('word2vec-google-news-300')\n",
    "\n",
    "def get_word_vectors(words: list):\n",
    "    \"\"\"\n",
    "    Returns word vectors represent words\n",
    "    :param words: iterable of words\n",
    "    :return: (len(words), dim) shaped numpy ndarrary which is word vectors\n",
    "    \"\"\"\n",
    "    words = [w for w in words if w in model.index_to_key]\n",
    "    return model[words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 300)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "tmp = get_word_vectors(['hello', 'world'])\n",
    "tmp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can get the word vectors for words in A, B, X, and Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = get_word_vectors(data_dict[A_key])\n",
    "B = get_word_vectors(data_dict[B_key])\n",
    "X = get_word_vectors(data_dict[X_key])\n",
    "Y = get_word_vectors(data_dict[Y_key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing association scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can compute \n",
    "\n",
    "$$\n",
    "s(w, A, B) = \\operatorname{mean}_{a \\in A} \\cos (\\vec{w}, \\vec{a})-\\operatorname{mean}_{b \\in B} \\cos (\\vec{w}, \\vec{b})\n",
    "$$\n",
    "\n",
    "for all $\\vec{w} \\in \\mathbf{X}$ and all $\\vec{w} \\in \\mathbf{Y}$, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this, we'll need **two helper functions**: \n",
    "\n",
    "1. one that normalized the word vectors to unit vectors, and \n",
    "2. another that can compute the consine similarity between two matrices. \n",
    "\n",
    "I have already implemented them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(vec):\n",
    "    return vec / np.linalg.norm(vec)\n",
    "\n",
    "def cos_sim(v1, v2):\n",
    "    return np.clip(np.tensordot(norm(v1), norm(v2), axes=(-1, -1)), -1.0, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 300)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's illustrate how `cos_sim()` works for $\\mathbf{A}$ &mdash; our (8, 300) the matrix of embeddings from the list of 'Male attributes'.\n",
    "\n",
    "We'll start with only the first row vector in $\\mathbf{X}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01323731, 0.02442578, 0.01441231, 0.02500675, 0.01759214,\n",
       "       0.01765213, 0.01422933, 0.011844  ], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get first vector in X\n",
    "w = X[0,:]\n",
    "# TODO: compute w's similarity with each row-vector in A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since A has 8 rows, we get 8 similarity scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But to compute $\\operatorname{mean}_{a \\in A} \\cos (\\vec{w}, \\vec{a})$ for $w$, we want to *average* these simiarities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.017299969"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: compute the mean of w's similarity with each row-vector in A (i.e., what you've computed in the previois cell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the first element in the WEAT forumla, we compute \n",
    "\n",
    "$$\n",
    "s(w, A, B) =\\operatorname{mean}_{a \\in A} \\cos (\\vec{w}, \\vec{a})-\\operatorname{mean}_{b \\in B} \\cos (\\vec{w}, \\vec{b})\n",
    "$$\n",
    "\n",
    "In code, this is just:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.00994616"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: compute w's average similarity with row-vectors in A and subtract w's average similarity with row-vectors in B from it "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference is negative, because $w$ is on average slightly more similar to terms in B than to terms in A."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But, of course, we want to compute these quantities for each vector in X and Y, respectively.\n",
    "\n",
    "Our `cos_sim()` function is able to handle this case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 8)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim(X, A).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have \n",
    "\n",
    "- eight rows, one for each term in **X**, and \n",
    "- eight colums, one for each term in **A**.\n",
    "\n",
    "So to get one average similarity score per term in **X** we need to compute **_row averages_** (like `rowMeans` in R):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00826428, 0.0025126 , 0.02507891, 0.01546477], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# note: this code might be new to you, so I've added it\n",
    "cos_sim(X[:4,:], A).mean(axis=1) # <== summarize over columns (i.e. at row level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So to get to the final _list of assiociaton scores_, we compute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.0033414 , -0.00068688,  0.00613773, -0.00046975, -0.00211891,\n",
       "       -0.00664737,  0.00016545,  0.00185493], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: compute X's row-vectors' average similarities' with row-vectors in A and \n",
    "#       subtract X's row-vectors' average similarity with row-vectors in B from it "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a custom function that does just that for input matrices W, A, and B:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://github.com/chadaeun/weat_replication/blob/0753713a47333827ef9f653d85e08740834ef698/lib/weat.py#L21C3-L21C3\n",
    "def weat_association(W, A, B):\n",
    "    \"\"\"\n",
    "    Returns association of the word w in W with the attribute for WEAT score.\n",
    "    s(w, A, B)\n",
    "    :param W: target words' vector representations\n",
    "    :param A: attribute words' vector representations\n",
    "    :param B: attribute words' vector representations\n",
    "    :return: (len(W), ) shaped numpy ndarray. each rows represent association of the word w in W\n",
    "    \"\"\"\n",
    "    # TODO: add the code from the previous cell here\n",
    "    return # TODO: return the final result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the differential association score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we want to get from\n",
    "\n",
    "$$\n",
    "s(w, A, B) =\\operatorname{mean}_{a \\in A} \\cos (\\vec{w}, \\vec{a})-\\operatorname{mean}_{b \\in B} \\cos (\\vec{w}, \\vec{b})\n",
    "$$\n",
    "\n",
    "to the **differential association** score:\n",
    "\n",
    "$$\n",
    "s(X, Y, A, B)=\\sum_{x \\in X} s(x, A, B)-\\sum_{y \\in Y} s(y, A, B)\n",
    "$$\n",
    "\n",
    "To this end, we need to sum the the outputs of `weat_association` for both X and Y and subtract them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04221046296879649"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: ensure that this call returns the value printend below the cell\n",
    "sum(weat_association(X, A, B))-sum(weat_association(Y, A, B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's wrap this last line of code in a function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://github.com/chadaeun/weat_replication/blob/0753713a47333827ef9f653d85e08740834ef698/lib/weat.py#L33C1-L43C81\n",
    "def weat_differential_association(X, Y, A, B):\n",
    "    \"\"\"\n",
    "    Returns differential association of two sets of target words with the attribute for WEAT score.\n",
    "    s(X, Y, A, B)\n",
    "    :param X: target words' vector representations\n",
    "    :param Y: target words' vector representations\n",
    "    :param A: attribute words' vector representations\n",
    "    :param B: attribute words' vector representations\n",
    "    :return: differential association (float value)\n",
    "    \"\"\"\n",
    "    return np.sum(weat_association(X, A, B)) - np.sum(weat_association(Y, A, B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall what our A, B, X, and Y terms are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: ['brother', 'father', 'uncle', 'grandfather', 'son', 'he', 'his', 'him']\n",
      "B: ['sister', 'mother', 'aunt', 'grandmother', 'daughter', 'she', 'hers', 'her']\n",
      "X: ['science', 'technology', 'physics', 'chemistry', 'einstein', 'nasa', 'experiment', 'astronomy']\n",
      "Y: ['poetry', 'art', 'shakespeare', 'dance', 'literature', 'novel', 'symphony', 'drama']\n"
     ]
    }
   ],
   "source": [
    "print('A:', data_dict[A_key])\n",
    "print('B:', data_dict[B_key])\n",
    "print('X:', data_dict[X_key])\n",
    "print('Y:', data_dict[Y_key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.042210463"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weat_differential_association(X, Y, A, B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation:** \n",
    "The fact that the differential association score is positive indicates that, taken together, the science target words are on average more associated with male than female terms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the effect size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But to get at the **effect size** for the WEAT (the \"normalized measure of how separated the distributions of associations between the target and attribute\"), we need to compute\n",
    "\n",
    "$$\n",
    "\\frac{\\operatorname{mean}_{x \\in X} s(x, A, B)-\\operatorname{mean}_{y \\in Y} s(y, A, B)}{\\operatorname{std} \\_\\operatorname{dev}_{w \\in X \\cup Y} s(w, A, B)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1951625"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_association = # TODO: compute the weat association score with (X, A, B)\n",
    "y_association = # TODO: compute the weat association score with (Y, A, B)\n",
    "tmp1 = x_association.mean() - y_association.mean()\n",
    "tmp2 = np.std(np.concatenate((x_association, y_association), axis=0)) # <== the \"union\" of X and Y is just the concatenation of the two\n",
    "\n",
    "effect_size = tmp1/tmp2\n",
    "effect_size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's wrap this in a function as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weat_score(X, Y, A, B):\n",
    "    \"\"\"\n",
    "    Returns WEAT score\n",
    "    X, Y, A, B must be (len(words), dim) shaped numpy ndarray\n",
    "    CAUTION: this function assumes that there's no intersection word between X and Y\n",
    "    :param X: target words' vector representations\n",
    "    :param Y: target words' vector representations\n",
    "    :param A: attribute words' vector representations\n",
    "    :param B: attribute words' vector representations\n",
    "    :return: WEAT score\n",
    "    \"\"\"\n",
    "\n",
    "    x_association = weat_association(X, A, B)\n",
    "    y_association = weat_association(Y, A, B)\n",
    "\n",
    "    tmp1 = np.mean(x_association, axis=-1) - np.mean(y_association, axis=-1)\n",
    "    tmp2 = np.std(np.concatenate((x_association, y_association), axis=0))\n",
    "\n",
    "    return tmp1 / tmp2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "advanced_text_analysis_gesis_2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
