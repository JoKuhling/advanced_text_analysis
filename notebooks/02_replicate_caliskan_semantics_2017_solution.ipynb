{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replication of Caliskan et al. \"Semantics derived automatically from language corpora contain human-like biases\"\n",
    "\n",
    "| Author | Last update |\n",
    "|:------ |:----------- |\n",
    "| Hauke Licht (https://github.com/haukelicht) | 2023-09-26 |\n",
    "\n",
    "In their often-cited *Science* [publication](https://www.science.org/doi/10.1126/science.aal4230) \"Semantics derived automatically from language corpora contain human-like biases,\" Caliskan, Bryson, and Narayanan propose a method for quantifying the biases captured in word embedding models.\n",
    "\n",
    "In their abstract, they write:\n",
    "\n",
    "> ... we show that applying machine learning to ordinary human language results in human-like semantic biases. \n",
    "> We replicate aspectrum of known biases, as measured by the *Implicit Association Test*, using a widely used, purely statistical machine-learning model trained on a standard corpus of text from the Web.\n",
    "> Our results indicate that text corpora contain recoverable and accurate imprints of our historic biases, whether morally neutral as towards insects or flowers, problematic as towards race or gender, or even simply veridical, reflecting the status quo distribution of gender with respect to careers or first names.\n",
    "\n",
    "\n",
    "## Replication: goals and approach\n",
    "\n",
    "In this notebook, we replicate their analyses.\n",
    "Out goal is to see if we find the same patterns they describe in their publication.\n",
    "We do this using their original word lists but a different word embedding model.\n",
    "\n",
    "Our replication will focus on their **WEAT** metric â€“ the *Word Embedding Association Test*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Before we can get going, let's set up our notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import gensim\n",
    "import gensim.downloader as api\n",
    "\n",
    "data_path =  os.path.join('..', 'data', 'replications', 'caliskan_semantics_2017')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Note:_** \n",
    "We'll work with data collected by Github user `chadaeun` for his 'weat_replication' project.\n",
    "The data relavant data is available at https://github.com/chadaeun/weat_replication/blob/master/weat/weat.json and has already been downloaded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The WEAT\n",
    "\n",
    "Let\n",
    "\n",
    "- $X$ and $Y$ be two sets of **_target words_** of equal size (to be tested for association), and\n",
    "- $A$ and $B$ the two sets of **_attribute words_** (indciating conceptual opposites).\n",
    "\n",
    "#### Example\n",
    "\n",
    "- The *target words* could be occupations ('programmer', 'engineer', 'scientist'; and 'nurse', 'teacher', 'librarian').\n",
    "- The two sets of *attribute words* could be ('man', 'male') and ('woman', 'female').\n",
    "\n",
    "#### Formula\n",
    "\n",
    "The test statistic $s$ of the word-embedding association test (WEAT) is defined as \n",
    "\n",
    "$$\n",
    "s(X, Y, A, B)=\\sum_{x \\in X} s(x, A, B)-\\sum_{y \\in Y} s(y, A, B)\n",
    "$$\n",
    "\n",
    "where \n",
    "\n",
    "$$\n",
    "s(w, A, B) =\\operatorname{mean}_{a \\in A} \\cos (\\vec{w}, \\vec{a})-\\operatorname{mean}_{b \\in B} \\cos (\\vec{w}, \\vec{b})\n",
    "$$\n",
    "\n",
    "measures the association of $w$ with the attribute, and\n",
    "$s(X,Y,A,B)$ measures the differential association of the two sets of target words $A$ and $B$ with the attribute.\n",
    "\n",
    "The **null hypothesis** is that there is no difference between the two sets of target words in terms of their relative similarity to the two sets of attribute words, i.e., $\\text{H}_0: s = 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example with code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the lists of target and attribute words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first load the dictionary of wordlists Caliskan et al. (2017) used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = os.path.join(data_path, 'wordlists.json')\n",
    "wordlists = json.load(open(fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Careers_Female_Male',\n",
       " 'EuropeanAmerican_AfricanAmerican_Pleasant_Unpleasant',\n",
       " 'EuropeanAmerican_AfricanAmerican_Pleasant_Unpleasant_2',\n",
       " 'Flowers_Insects_Pleasant_Unpleasant',\n",
       " 'Male_Female_Career_Family',\n",
       " 'Math_Arts_Male_Female',\n",
       " 'MusicalInstruments_Weapons_Pleasant_Unpleasant',\n",
       " 'Names_Female_Male',\n",
       " 'Science_Arts_Male_Female']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(wordlists.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with the example of the WEAT for science and art attributes with target words representing the concepts \"male\" and \"female\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['A_key', 'Arts words', 'B_key', 'Female attributes', 'Male attributes', 'Science words', 'X_key', 'Y_key', 'attributes', 'method', 'targets'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict = wordlists['Science_Arts_Male_Female']\n",
    "data_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Note:_** Each top-level dictionary element contains a dictionary with the same set of keys."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to use the following attribute words list for A and B:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: ['brother', 'father', 'uncle', 'grandfather', 'son', 'he', 'his', 'him']\n",
      "B: ['sister', 'mother', 'aunt', 'grandmother', 'daughter', 'she', 'hers', 'her']\n"
     ]
    }
   ],
   "source": [
    "A_key = data_dict['A_key']\n",
    "print('A:', data_dict[A_key])\n",
    "B_key = data_dict['B_key']\n",
    "print('B:', data_dict[B_key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And for the target words X and Y, we use the following word lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: ['science', 'technology', 'physics', 'chemistry', 'einstein', 'nasa', 'experiment', 'astronomy']\n",
      "Y: ['poetry', 'art', 'shakespeare', 'dance', 'literature', 'novel', 'symphony', 'drama']\n"
     ]
    }
   ],
   "source": [
    "X_key = data_dict['X_key']\n",
    "print('X:', data_dict[X_key])\n",
    "Y_key = data_dict['Y_key']\n",
    "print('Y:', data_dict[Y_key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a pre-trained embedding model and get target and attribute words' embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to get these words embeddings.\n",
    "We'll use a word2vec model available with `gensim` and use a helper function to extract word vectors from it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import numpy as np\n",
    "\n",
    "model = api.load('word2vec-google-news-300')\n",
    "\n",
    "def get_word_vectors(words: list):\n",
    "    \"\"\"\n",
    "    Returns word vectors represent words\n",
    "    :param words: iterable of words\n",
    "    :return: (len(words), dim) shaped numpy ndarrary which is word vectors\n",
    "    \"\"\"\n",
    "    words = [w for w in words if w in model.index_to_key]\n",
    "    return model[words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 300)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "tmp = get_word_vectors(['hello', 'world'])\n",
    "tmp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can get the word vectors for words in A, B, X, and Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = get_word_vectors(data_dict[A_key])\n",
    "B = get_word_vectors(data_dict[B_key])\n",
    "X = get_word_vectors(data_dict[X_key])\n",
    "Y = get_word_vectors(data_dict[Y_key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important that A and B, and X and Y have the same numbers of rows!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert A.shape[0] == B.shape[0]\n",
    "assert X.shape[0] == Y.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing association scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can compute \n",
    "\n",
    "$$\n",
    "s(w, A, B) = \\operatorname{mean}_{a \\in A} \\cos (\\vec{w}, \\vec{a})-\\operatorname{mean}_{b \\in B} \\cos (\\vec{w}, \\vec{b})\n",
    "$$\n",
    "\n",
    "for all $\\vec{w} \\in \\mathbf{X}$ and all $\\vec{w} \\in \\mathbf{Y}$, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this, we'll need **two helper functions**: \n",
    "\n",
    "1. one that normalized the word vectors to unit vectors, and \n",
    "2. another that can compute the consine similarity between two matrices. \n",
    "\n",
    "I have already implemented them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(vec):\n",
    "    return vec / np.linalg.norm(vec)\n",
    "\n",
    "def cos_sim(v1, v2):\n",
    "    return np.clip(np.tensordot(norm(v1), norm(v2), axes=(-1, -1)), -1.0, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 300)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's illustrate how `cos_sim()` works for $\\mathbf{A}$ &mdash; our (8, 300) the matrix of embeddings from the list of 'Male attributes'.\n",
    "\n",
    "We'll start with only the first row vector in $\\mathbf{X}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01323731, 0.02442578, 0.01441231, 0.02500675, 0.01759214,\n",
       "       0.01765213, 0.01422933, 0.011844  ], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get first vector in X\n",
    "w = X[0,:]\n",
    "# compute w's similarity with each row-vector in A\n",
    "cos_sim(w, A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since A has 8 rows, we get 8 similarity scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But to compute $\\operatorname{mean}_{a \\in A} \\cos (\\vec{w}, \\vec{a})$ for $w$, we want to *average* these simiarities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.017299969"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim(w, A).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the first element in the WEAT forumla, we compute \n",
    "\n",
    "$$\n",
    "s(w, A, B) =\\operatorname{mean}_{a \\in A} \\cos (\\vec{w}, \\vec{a})-\\operatorname{mean}_{b \\in B} \\cos (\\vec{w}, \\vec{b})\n",
    "$$\n",
    "\n",
    "In code, this is just:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.00994616"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim(w, A).mean() - cos_sim(w, B).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference is negative, because $w$ is on average slightly more similar to terms in B than to terms in A."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But, of course, we want to compute these quantities for each vector in X and Y, respectively.\n",
    "\n",
    "Our `cos_sim()` function is able to handle this case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 8)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim(X, A).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have \n",
    "\n",
    "- eight rows, one for each term in **X**, and \n",
    "- eight colums, one for each term in **A**.\n",
    "\n",
    "So to get one average similarity score per term in **X** we need to compute **_row averages_** (like `rowMeans` in R):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00826428, 0.0025126 , 0.02507891, 0.01546477], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim(X[:4,:], A).mean(axis=1) # <== summarize over columns (i.e. at row level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So to get to the final _list of assiociaton scores_, we compute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.0033414 , -0.00068688,  0.00613773, -0.00046975, -0.00211891,\n",
       "       -0.00664737,  0.00016545,  0.00185493], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim(X, A).mean(axis=1)-cos_sim(X, B).mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a custom function that does just that for input matrices W, A, and B:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://github.com/chadaeun/weat_replication/blob/0753713a47333827ef9f653d85e08740834ef698/lib/weat.py#L21C3-L21C3\n",
    "def weat_association(W, A, B):\n",
    "    \"\"\"\n",
    "    Returns association of the word w in W with the attribute for WEAT score.\n",
    "    s(w, A, B)\n",
    "    :param W: target words' vector representations\n",
    "    :param A: attribute words' vector representations\n",
    "    :param B: attribute words' vector representations\n",
    "    :return: (len(W), ) shaped numpy ndarray. each rows represent association of the word w in W\n",
    "    \"\"\"\n",
    "    return cos_sim(W, A).mean(axis=1) - cos_sim(W, B).mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the differential association score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we want to get from\n",
    "\n",
    "$$\n",
    "s(w, A, B) =\\operatorname{mean}_{a \\in A} \\cos (\\vec{w}, \\vec{a})-\\operatorname{mean}_{b \\in B} \\cos (\\vec{w}, \\vec{b})\n",
    "$$\n",
    "\n",
    "to the **differential association** score:\n",
    "\n",
    "$$\n",
    "s(X, Y, A, B)=\\sum_{x \\in X} s(x, A, B)-\\sum_{y \\in Y} s(y, A, B)\n",
    "$$\n",
    "\n",
    "To this end, we need to sum the the outputs of `weat_association` for both X and Y and subtract them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04221046296879649"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(weat_association(X, A, B))-sum(weat_association(Y, A, B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's wrap this last line of code in a function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://github.com/chadaeun/weat_replication/blob/0753713a47333827ef9f653d85e08740834ef698/lib/weat.py#L33C1-L43C81\n",
    "def weat_differential_association(X, Y, A, B):\n",
    "    \"\"\"\n",
    "    Returns differential association of two sets of target words with the attribute for WEAT score.\n",
    "    s(X, Y, A, B)\n",
    "    :param X: target words' vector representations\n",
    "    :param Y: target words' vector representations\n",
    "    :param A: attribute words' vector representations\n",
    "    :param B: attribute words' vector representations\n",
    "    :return: differential association (float value)\n",
    "    \"\"\"\n",
    "    return np.sum(weat_association(X, A, B)) - np.sum(weat_association(Y, A, B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall what our A, B, X, and Y terms are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: ['brother', 'father', 'uncle', 'grandfather', 'son', 'he', 'his', 'him']\n",
      "B: ['sister', 'mother', 'aunt', 'grandmother', 'daughter', 'she', 'hers', 'her']\n",
      "X: ['science', 'technology', 'physics', 'chemistry', 'einstein', 'nasa', 'experiment', 'astronomy']\n",
      "Y: ['poetry', 'art', 'shakespeare', 'dance', 'literature', 'novel', 'symphony', 'drama']\n"
     ]
    }
   ],
   "source": [
    "print('A:', data_dict[A_key])\n",
    "print('B:', data_dict[B_key])\n",
    "print('X:', data_dict[X_key])\n",
    "print('Y:', data_dict[Y_key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.042210463"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weat_differential_association(X, Y, A, B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation:** \n",
    "The fact that the differential association score is positive indicates that, taken together, the science target words are on average more associated with male than female terms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the effect size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But to get at the **effect size** for the WEAT (the \"normalized measure of how separated the distributions of associations between the target and attribute\"), we need to compute\n",
    "\n",
    "$$\n",
    "\\frac{\\operatorname{mean}_{x \\in X} s(x, A, B)-\\operatorname{mean}_{y \\in Y} s(y, A, B)}{\\operatorname{std} \\_\\operatorname{dev}_{w \\in X \\cup Y} s(w, A, B)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1951625"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_association = weat_association(X, A, B)\n",
    "y_association = weat_association(Y, A, B)\n",
    "tmp1 = x_association.mean() - y_association.mean()\n",
    "tmp2 = np.std(np.concatenate((x_association, y_association), axis=0)) # <== the \"union\" of X and Y is just the concatenation of the two\n",
    "\n",
    "effect_size = tmp1/tmp2\n",
    "effect_size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's wrap this in a function as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weat_score(X, Y, A, B):\n",
    "    \"\"\"\n",
    "    Returns WEAT score\n",
    "    X, Y, A, B must be (len(words), dim) shaped numpy ndarray\n",
    "    CAUTION: this function assumes that there's no intersection word between X and Y\n",
    "    :param X: target words' vector representations\n",
    "    :param Y: target words' vector representations\n",
    "    :param A: attribute words' vector representations\n",
    "    :param B: attribute words' vector representations\n",
    "    :return: WEAT score\n",
    "    \"\"\"\n",
    "\n",
    "    x_association = weat_association(X, A, B)\n",
    "    y_association = weat_association(Y, A, B)\n",
    "\n",
    "    tmp1 = np.mean(x_association, axis=-1) - np.mean(y_association, axis=-1)\n",
    "    tmp2 = np.std(np.concatenate((x_association, y_association), axis=0))\n",
    "\n",
    "    return tmp1 / tmp2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete replication: Get WEAT scores for different target and attribute term pairings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our wordlist object contains more sets of words to compute the WEAT:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EuropeanAmerican_AfricanAmerican_Pleasant_Unpleasant',\n",
       " 'EuropeanAmerican_AfricanAmerican_Pleasant_Unpleasant_2',\n",
       " 'Flowers_Insects_Pleasant_Unpleasant',\n",
       " 'Male_Female_Career_Family',\n",
       " 'Math_Arts_Male_Female',\n",
       " 'MusicalInstruments_Weapons_Pleasant_Unpleasant',\n",
       " 'Science_Arts_Male_Female']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[k for k, v in wordlists.items() if v['method'] == 'weat']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So let's loop over these tests to compute WEAT effect sizes for each.\n",
    "But first, we'll add a helper function that handles the case of imbalanced word lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source = https://github.com/chadaeun/weat_replication/blob/master/lib/utils.py#L116C1-L133C16\n",
    "def balance_word_vectors(A: np.ndarray, B: np.ndarray):\n",
    "    \"\"\"\n",
    "    Balance size of two lists of word vectors by randomly deleting some vectors in larger one.\n",
    "    If there are words that did not occur in the corpus, some words will ignored in get_word_vectors.\n",
    "    So result word vectors' size can be unbalanced.\n",
    "    :param A: (len(words), dim) shaped numpy ndarrary which is word vectors\n",
    "    :param B: (len(words), dim) shaped numpy ndarrary which is word vectors\n",
    "    :return: tuple of two balanced word vectors\n",
    "    \"\"\"\n",
    "\n",
    "    diff = len(A) - len(B)\n",
    "\n",
    "    if diff > 0:\n",
    "        A = np.delete(A, np.random.choice(len(A), diff, 0), axis=0)\n",
    "    else:\n",
    "        B = np.delete(B, np.random.choice(len(B), -diff, 0), axis=0)\n",
    "\n",
    "    return A, B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to compute the WEAT effect sizes for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "# adapted from https://github.com/chadaeun/weat_replication/blob/master/weat_test.py#L26-82\n",
    "for data_name, data_dict in wordlists.items():\n",
    "    \n",
    "    if data_dict['method'] == 'wefat':\n",
    "        continue\n",
    "    \n",
    "    A = get_word_vectors(data_dict[data_dict['A_key']])\n",
    "    B = get_word_vectors(data_dict[data_dict['B_key']])\n",
    "    \n",
    "    A, B = balance_word_vectors(A, B)\n",
    "    \n",
    "    num_attr = len(A)    \n",
    "    \n",
    "    X = get_word_vectors(data_dict[data_dict['X_key']])\n",
    "    Y = get_word_vectors(data_dict[data_dict['Y_key']])\n",
    "\n",
    "    X, Y = balance_word_vectors(X, Y)\n",
    "    \n",
    "    num_target = len(X)\n",
    "\n",
    "    score = weat_score(X, Y, A, B)\n",
    "\n",
    "    res.append([data_name, data_dict['targets'], data_dict['attributes'], data_dict['method'], score, num_target, num_attr])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarize the results in a Table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Targets</th>\n",
       "      <th>Attributes</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>European American names vs African American names</td>\n",
       "      <td>Pleasant vs Unpleasant</td>\n",
       "      <td>-0.599945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>European American names vs African American names</td>\n",
       "      <td>Pleasant vs Unpleasant</td>\n",
       "      <td>-0.121617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Flowers vs Insects</td>\n",
       "      <td>Pleasant vs Unpleasant</td>\n",
       "      <td>1.528112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Male names vs Female names</td>\n",
       "      <td>Career words vs Family words</td>\n",
       "      <td>1.519103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Math words vs Arts Words</td>\n",
       "      <td>Male attributes vs Female attributes</td>\n",
       "      <td>0.932301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Musical instruments vs Weapons</td>\n",
       "      <td>Pleasant vs Unpleasant</td>\n",
       "      <td>1.615366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Science words vs Arts words</td>\n",
       "      <td>Male attributes vs Female attributes</td>\n",
       "      <td>1.195163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Targets  \\\n",
       "0  European American names vs African American names   \n",
       "1  European American names vs African American names   \n",
       "2                                 Flowers vs Insects   \n",
       "3                         Male names vs Female names   \n",
       "4                           Math words vs Arts Words   \n",
       "5                     Musical instruments vs Weapons   \n",
       "6                        Science words vs Arts words   \n",
       "\n",
       "                             Attributes     Score  \n",
       "0                Pleasant vs Unpleasant -0.599945  \n",
       "1                Pleasant vs Unpleasant -0.121617  \n",
       "2                Pleasant vs Unpleasant  1.528112  \n",
       "3          Career words vs Family words  1.519103  \n",
       "4  Male attributes vs Female attributes  0.932301  \n",
       "5                Pleasant vs Unpleasant  1.615366  \n",
       "6  Male attributes vs Female attributes  1.195163  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "result_df = pd.DataFrame(res, columns=['Data Name', 'Targets', 'Attributes', 'Method', 'Score', '# of target words', '# of attribute words'])\n",
    "result_df[['Targets', 'Attributes', 'Score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caliskan report the following numbers in their paper:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Targets | Attibutes | WEAT | $p$-value |\n",
    "|:------- |:--------- |:---- |:--------- | \n",
    "| European-American vs. African-American names\t|\tPleasant vs. unpleasant\t|\t1.41\t|\t$10^{âˆ’8}$ |\n",
    "| Flowers vs. insects\t|\tPleasant vs. unpleasant\t|\t1.50\t|\t$10^{âˆ’7}$ |\n",
    "| Male vs. female names\t|\tCareer vs. family\t|\t1.81\t|\t$10^{âˆ’3}$ |\n",
    "| Instruments vs. weapons\t|\tPleasant vs. unpleasant\t|\t1.53\t|\t$10^{âˆ’7}$ |\n",
    "| Science vs. arts\t|\tMale vs. female terms\t|\t1.24 | $10^{âˆ’2}$ |\n",
    "<!--| Mental vs. physical disease\t|\tTemporary vs. permanent\t|\t1.38\t|\t$10^{âˆ’2}$ |-->\n",
    "<!--| Young vs. old people's names\t|\tPleasant vs. unpleasant\t|\t1.21\t|\t$10^{âˆ’2}$ |-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the scores we obtain from the word2vec model are mostly prittey similar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing $p$-values\n",
    "\n",
    "What's missing so far, however, are $p$-values indicating whether our effect size point estimates are statistically significant.\n",
    "\n",
    "So lets' get back to our example of the association of Male and Female words with Science vs. Arts words: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: ['brother', 'father', 'uncle', 'grandfather', 'son', 'he', 'his', 'him']\n",
      "B: ['sister', 'mother', 'aunt', 'grandmother', 'daughter', 'she', 'hers', 'her']\n",
      "X: ['science', 'technology', 'physics', 'chemistry', 'einstein', 'nasa', 'experiment', 'astronomy']\n",
      "Y: ['poetry', 'art', 'shakespeare', 'dance', 'literature', 'novel', 'symphony', 'drama']\n"
     ]
    }
   ],
   "source": [
    "print('A:', data_dict[A_key])\n",
    "print('B:', data_dict[B_key])\n",
    "print('X:', data_dict[X_key])\n",
    "print('Y:', data_dict[Y_key])\n",
    "\n",
    "A = get_word_vectors(data_dict[A_key])\n",
    "B = get_word_vectors(data_dict[B_key])\n",
    "X = get_word_vectors(data_dict[X_key])\n",
    "Y = get_word_vectors(data_dict[Y_key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.042210463\n"
     ]
    }
   ],
   "source": [
    "# point estimate\n",
    "score = weat_differential_association(X, Y, A, B)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing the permutation test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The statistical significance of the point estimate is computed with ther **permutation test**.\n",
    "\n",
    "The perumatation test shuffles target words in X and Y between the two opposing categories and computes the WEAT association score $s$ for each reshuffle (\"perumtation\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we'll proceed as follows:\n",
    "\n",
    "1. we stack the matrices with word vectors for terms in *X* and *Y* on top of each other into a matrix **S**\n",
    "2. we create a list of all possible permutations of the row indexes of **S**\n",
    "3. we apply each list of indexes to extract rows in **S** and split it row-wise in half\n",
    "4. we compute the $s$ score with the two partitions of **S** instead of **X** and **Y**\n",
    "5. we compare the point estimate with the resulting WEAT association scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 300)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. stack \n",
    "S = np.concatenate([X, Y], axis=0)\n",
    "S.shape # <== has twice as many rows as X and Y, respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. create list of possible permutations\n",
    "# note: computing all perutations is not feasible, so we sample 500 permutations\n",
    "idxs = np.arange(X.shape[0]*2)\n",
    "# use numpy random generator to ensure reproducibility\n",
    "rng = np.random.default_rng(1234)\n",
    "permutations = [rng.permutation(idxs) for _ in range(500)]\n",
    "len(permutations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.00096521643, 0.018175641)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. iterate over permutations (reshuffled indexes), ... \n",
    "scores = []\n",
    "for p in permutations:\n",
    "    # partition stacked matrix in \"fake\" X and Y matrices ...\n",
    "    S_ = S[p,:]\n",
    "    X_ = S_[:X.shape[0]]\n",
    "    Y_ = S_[X.shape[0]:]\n",
    "    # ... and comute WEAT score\n",
    "    s = weat_differential_association(X_, Y_, A, B) \n",
    "    scores.append(s)\n",
    "scores = np.array(scores)\n",
    "\n",
    "# show distributoin of scores (should average to Â±0)\n",
    "scores.mean(), scores.std()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caliskan *et al.* note that the one-sided $p$-value is \n",
    "\n",
    "$$\n",
    "\\operatorname{Pr}_i\\left[s\\left(X_i, Y_i, A, B\\right)>s(X, Y, A, B)\\right]\n",
    "$$\n",
    "\n",
    "So we can compute this value by comparing our perumtation scores with the point estimate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.012"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. compute p-value for a given score\n",
    "pvalue = np.sum(scores > score) / len(scores)\n",
    "pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Note:_** Caliskan explain that this $p$-value 'is a normalized measure of how separated the two distributions (of associations between thetarget and attribute) are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's wrap this code in a function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weat_p_value(X, Y, A, B, seed=1234):\n",
    "    \"\"\"\n",
    "    Returns one-sided p-value of the permutation test for WEAT score\n",
    "    CAUTION: this function samples perumutations\n",
    "    :param X: target words' vector representations\n",
    "    :param Y: target words' vector representations\n",
    "    :param A: attribute words' vector representations\n",
    "    :param B: attribute words' vector representations\n",
    "    :return: p-value (float value)\n",
    "    \"\"\"\n",
    "    score = weat_differential_association(X, Y, A, B)\n",
    "    \n",
    "    # 1. stack \n",
    "    S = np.concatenate([X, Y], axis=0)\n",
    "    \n",
    "    # 2. permute indices\n",
    "    idxs = np.arange(X.shape[0]*2)\n",
    "    rng = np.random.default_rng(seed)\n",
    "    permutations = [rng.permutation(idxs) for _ in range(500)]\n",
    "    \n",
    "    scores = []\n",
    "\n",
    "    # 3. partition stacked matrix in \"fake\" X and Y matrices and comute WEAT scores\n",
    "    scores = np.array([weat_differential_association(S[p,:][:X.shape[0]], S[p,:][X.shape[0]:], A, B) for p in permutations])\n",
    "\n",
    "    # 4. compute p-value for a given score\n",
    "    pvalue = np.sum(scores > score) / len(scores)\n",
    "\n",
    "    return pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's again iterate over test cases in `wordlists` but now compute the WEAT score and its associated $p$-value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for data_name, data_dict in wordlists.items():\n",
    "    if data_dict['method'] == 'wefat':\n",
    "        continue\n",
    "    \n",
    "    A = get_word_vectors(data_dict[data_dict['A_key']])\n",
    "    B = get_word_vectors(data_dict[data_dict['B_key']])\n",
    "    \n",
    "    A, B = balance_word_vectors(A, B)\n",
    "    \n",
    "    X = get_word_vectors(data_dict[data_dict['X_key']])\n",
    "    Y = get_word_vectors(data_dict[data_dict['Y_key']])\n",
    "\n",
    "    X, Y = balance_word_vectors(X, Y)\n",
    "        \n",
    "    score = weat_score(X, Y, A, B)\n",
    "    pvalue = weat_p_value(X, Y, A, B)\n",
    "    \n",
    "    res.append([data_name, data_dict['targets'], data_dict['attributes'], data_dict['method'], score, pvalue])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Targets</th>\n",
       "      <th>Attributes</th>\n",
       "      <th>Score</th>\n",
       "      <th>P-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>European American names vs African American names</td>\n",
       "      <td>Pleasant vs Unpleasant</td>\n",
       "      <td>0.082838</td>\n",
       "      <td>0.458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>European American names vs African American names</td>\n",
       "      <td>Pleasant vs Unpleasant</td>\n",
       "      <td>-0.411707</td>\n",
       "      <td>0.762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Flowers vs Insects</td>\n",
       "      <td>Pleasant vs Unpleasant</td>\n",
       "      <td>1.528112</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Male names vs Female names</td>\n",
       "      <td>Career words vs Family words</td>\n",
       "      <td>1.519103</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Math words vs Arts Words</td>\n",
       "      <td>Male attributes vs Female attributes</td>\n",
       "      <td>0.932301</td>\n",
       "      <td>0.030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Musical instruments vs Weapons</td>\n",
       "      <td>Pleasant vs Unpleasant</td>\n",
       "      <td>1.610835</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Science words vs Arts words</td>\n",
       "      <td>Male attributes vs Female attributes</td>\n",
       "      <td>1.195163</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Targets  \\\n",
       "0  European American names vs African American names   \n",
       "1  European American names vs African American names   \n",
       "2                                 Flowers vs Insects   \n",
       "3                         Male names vs Female names   \n",
       "4                           Math words vs Arts Words   \n",
       "5                     Musical instruments vs Weapons   \n",
       "6                        Science words vs Arts words   \n",
       "\n",
       "                             Attributes     Score  P-value  \n",
       "0                Pleasant vs Unpleasant  0.082838    0.458  \n",
       "1                Pleasant vs Unpleasant -0.411707    0.762  \n",
       "2                Pleasant vs Unpleasant  1.528112    0.000  \n",
       "3          Career words vs Family words  1.519103    0.000  \n",
       "4  Male attributes vs Female attributes  0.932301    0.030  \n",
       "5                Pleasant vs Unpleasant  1.610835    0.000  \n",
       "6  Male attributes vs Female attributes  1.195163    0.012  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = pd.DataFrame(res, columns=['Data Name', 'Targets', 'Attributes', 'Method', 'Score', 'P-value'])\n",
    "result_df[['Targets', 'Attributes', 'Score', 'P-value']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "advanced_text_analysis_gesis_2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
