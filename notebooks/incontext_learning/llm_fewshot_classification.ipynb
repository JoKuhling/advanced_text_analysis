{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "025017f5",
   "metadata": {},
   "source": [
    "# Few-shot text classification with LLMs\n",
    "\n",
    "This notebook illustrates how to use different LLMs for text classification.\n",
    "\n",
    "- closed-source LLMs models by OpenAI\n",
    "- open-weights model hosted via Hugging Face Inference Providers/Endpoints\n",
    "- open-weights LLMs models with `ollama`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5afba0",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da313a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from src.utils.io import read_tabular\n",
    "import re\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f56a5d",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c7d6e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLAB = False # no support for colab yet\n",
    "base_path = Path(\"/content/advanced_text_analysis/\" if COLAB else \"../../\")\n",
    "data_path = base_path / \"data\" / \"labeled\" / \"benoit_crowdsourced_2016\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c8fc335",
   "metadata": {},
   "outputs": [],
   "source": [
    "## (down)load the data\n",
    "fp = data_path / \"benoit_crowdsourced_2016-policy_area.csv\"\n",
    "if not fp.exists():\n",
    "    url = \"https://cta-text-datasets.s3.eu-central-1.amazonaws.com/labeled/\" + fp.parent.name + '/' + fp.name\n",
    "    df = pd.read_csv(url)\n",
    "    fp.parent.mkdir(parents=True, exist_ok=True)\n",
    "    df.to_csv(fp, index=False)\n",
    "\n",
    "df = read_tabular(fp, columns=['uid', 'text', 'label', 'metadata__gold'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e5990bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset to gold examples (i.e., those labeled by experts)\n",
    "df = df[df.metadata__gold]\n",
    "del df['metadata__gold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8944ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "economic    225\n",
      "neither     181\n",
      "social      100\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "id2label = {\n",
    "    2: 'economic',\n",
    "    3: 'social',\n",
    "    1: 'neither',\n",
    "}\n",
    "df.label = df.label.map(id2label)\n",
    "\n",
    "print(df.label.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "562dda17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get 20 examples per label class\n",
    "inputs = df.groupby('label').sample(20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f817c7",
   "metadata": {},
   "source": [
    "#### sample few-shot examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d45ff30",
   "metadata": {},
   "outputs": [],
   "source": [
    "exemplars = df[~df.uid.isin(inputs.uid)].groupby('label').sample(3, random_state=42).reset_index(drop=True).sample(frac=1.0, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d1dae24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>50007221</td>\n",
       "      <td>We will: Ensure equality before the law for le...</td>\n",
       "      <td>social</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001031</td>\n",
       "      <td>State power is checked and opportunities are s...</td>\n",
       "      <td>economic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10009221</td>\n",
       "      <td>In the 40 years since 1945, more than 10 milli...</td>\n",
       "      <td>neither</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10001741</td>\n",
       "      <td>A Capital-Owning Democracy. Share Ownership. H...</td>\n",
       "      <td>economic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10007451</td>\n",
       "      <td>Those who commit serious crimes can now expect...</td>\n",
       "      <td>social</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20004571</td>\n",
       "      <td>These improvements will be paid for in part fr...</td>\n",
       "      <td>economic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10009181</td>\n",
       "      <td>We stand up vigorously for Britain's interests...</td>\n",
       "      <td>neither</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000501</td>\n",
       "      <td>Founded in Strength. The ability to act intern...</td>\n",
       "      <td>neither</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10007531</td>\n",
       "      <td>Building on Strength. We will continue to put ...</td>\n",
       "      <td>social</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        uid                                               text     label\n",
       "7  50007221  We will: Ensure equality before the law for le...    social\n",
       "1  10001031  State power is checked and opportunities are s...  economic\n",
       "5  10009221  In the 40 years since 1945, more than 10 milli...   neither\n",
       "0  10001741  A Capital-Owning Democracy. Share Ownership. H...  economic\n",
       "8  10007451  Those who commit serious crimes can now expect...    social\n",
       "2  20004571  These improvements will be paid for in part fr...  economic\n",
       "4  10009181  We stand up vigorously for Britain's interests...   neither\n",
       "3  10000501  Founded in Strength. The ability to act intern...   neither\n",
       "6  10007531  Building on Strength. We will continue to put ...    social"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exemplars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bace6133",
   "metadata": {},
   "source": [
    "We use these \"exemplars\" in the conversation history to demonstrate the disred annotation behavior.\n",
    "\n",
    "For this, we have to format them in **turns** of input text and assistants response (using the observed \"true\" label):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bfefe121",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_template = \"Text: '''{text}'''\"\n",
    "\n",
    "def get_exemplar_messages(exemplars):\n",
    "    exemplar_messages = []\n",
    "    for _, row in exemplars.iterrows():\n",
    "        exemplar_messages.append({\"role\": \"user\", \"content\": text_template.format(text=row.text)})\n",
    "        exemplar_messages.append({\"role\": \"assistant\", \"content\": f\"{row.label}\"})\n",
    "    return exemplar_messages\n",
    "\n",
    "exemplar_messages = get_exemplar_messages(exemplars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65d4beb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': \"Text: '''We will: Ensure equality before the law for lesbians and gay men through our new Human Rights Commission and the Bill of Rights.'''\"},\n",
       " {'role': 'assistant', 'content': 'social'},\n",
       " {'role': 'user',\n",
       "  'content': \"Text: '''State power is checked and opportunities are spread throughout society.'''\"},\n",
       " {'role': 'assistant', 'content': 'economic'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exemplar_messages[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e11918",
   "metadata": {},
   "source": [
    "## Define the task\n",
    "\n",
    "In this example, we adapt the instruction for one of the tweet classification tasks examined in Benoit et al. ([2016](https://doi.org/10.1017/S0003055416000058)) \"Crowd-sourced Text Analysis: Reproducible and Agile Production\n",
    "of Political Data\"\n",
    "\n",
    "- see [this README file](../../data/labeled/benoit_crowdsourced_2016/README.md) for a description of the data and tasks covered in the paper\n",
    "- see [this file](../../data/labeled/benoit_crowdsourced_2016/instructions/econ_social_policy.md) for a copy of their original task instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "903e86b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = f\"\"\"\n",
    "Act as a text classification system versatile in performing content analysis.\n",
    "\n",
    "You will read a sentence from a political text.\n",
    "Yout will judge whether this sentence deals with economic or social policy.\n",
    "You must classify posts into one of the following categories: \"economic\", \"social\", or \"neither\". \n",
    "\n",
    "## Definitions\n",
    "\n",
    "These categories have the following definitions:\n",
    "\n",
    "- Sentences should be coded as \"economic\" if they deal with aspects of the economy, such as: Taxation, Government spending, Services provided by the government or other public bodies, Pensions, unemployment and welfare benefits, and other state benefits, Property, investment and share ownership, public or private, Interest rates and exchange rates, Regulation of economic activity, public or private, Relations between employers, workers and trade unions\n",
    "- Sentences should be coded as \"social\" if they deal with aspects of social and moral life, relationships between social groups, and matters of national and social identity. These include: Policing, crime, punishment and rehabilitation of offenders; Immigration, relations between social groups, discrimination and multiculturalism; The role of the state in regulating the social and moral behavior of individuals\n",
    "\n",
    "## Step-by-step instructions\n",
    "\n",
    "Follow these steps to classify the sentence:\n",
    "\n",
    "1. Carefully read the text of the sentence, paying close attention to details.\n",
    "2. Assess whether the sentence belongs to any of the categories. If not, return 'neither' as your response.\n",
    "3. Classify the sentence with the category it belongs to. Return only the name of the category.\n",
    "\n",
    "## Response format\n",
    "\n",
    "Only include the selected category in your response and no further text.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95844713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['They are no longer content that some of the most important decisions in their lives what school their children attend, for example, or whether or not to go on strike should be taken by officialdom or trade union bosses.',\n",
       " 'Any extra burden on business will destroy jobs.',\n",
       " 'We will increase the bonus by paying a double pension in the first week of December.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = inputs.text.to_list()\n",
    "texts[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9773717a",
   "metadata": {},
   "source": [
    "## With ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90464e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "MODEL = 'gpt-4o-2024-08-06'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564d1d75",
   "metadata": {},
   "source": [
    "#### illustration with a _single_ sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48e912bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'system', 'content': '\\nAct as a text classification system versatile in performing content analysis.\\n\\nYou will read a sentence from a political text.\\nYout will judge whether this sentence deals with economic or social policy.\\nYou must classify posts into one of the following categories: \"economic\", \"social\", or \"neither\". \\n\\n## Definitions\\n\\nThese categories have the following definitions:\\n\\n- Sentences should be coded as \"economic\" if they deal with aspects of the economy, such as: Taxation, Government spending, Services provided by the government or other public bodies, Pensions, unemployment and welfare benefits, and other state benefits, Property, investment and share ownership, public or private, Interest rates and exchange rates, Regulation of economic activity, public or private, Relations between employers, workers and trade unions\\n- Sentences should be coded as \"social\" if they deal with aspects of social and moral life, relationships between social groups, and matters of national and social identity. These include: Policing, crime, punishment and rehabilitation of offenders; Immigration, relations between social groups, discrimination and multiculturalism; The role of the state in regulating the social and moral behavior of individuals\\n\\n## Step-by-step instructions\\n\\nFollow these steps to classify the sentence:\\n\\n1. Carefully read the text of the sentence, paying close attention to details.\\n2. Assess whether the sentence belongs to any of the categories. If not, return \\'neither\\' as your response.\\n3. Classify the sentence with the category it belongs to. Return only the name of the category.\\n\\n## Response format\\n\\nOnly include the selected category in your response and no further text.\\n'}\n",
      "{'role': 'user', 'content': \"Text: '''And that Labour's much-vaunted pay pact with the unions collapsed in the industrial anarchy of the winter of discontent, n which the dead went unburied, rubbish piled up in the streets and the country was gripped by a creeping paralysis which Labour was powerless to cure?'''\"}\n"
     ]
    }
   ],
   "source": [
    "text = df.text.iloc[5]\n",
    "# print(text)\n",
    "\n",
    "messages = [\n",
    "    # system prompt\n",
    "    {\"role\": \"system\", \"content\": instructions},\n",
    "    # user input\n",
    "    {\"role\": \"user\", \"content\": text_template.format(text=text)},\n",
    "]\n",
    "print(*messages, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d99d0bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'system', 'content': '\\nAct as a text classification system versatile in performing content analysis.\\n\\nYou will read a sentence from a political text.\\nYout will judge whether this sentence deals with economic or social policy.\\nYou must classify posts into one of the following categories: \"economic\", \"social\", or \"neither\". \\n\\n## Definitions\\n\\nThese categories have the following definitions:\\n\\n- Sentences should be coded as \"economic\" if they deal with aspects of the economy, such as: Taxation, Government spending, Services provided by the government or other public bodies, Pensions, unemployment and welfare benefits, and other state benefits, Property, investment and share ownership, public or private, Interest rates and exchange rates, Regulation of economic activity, public or private, Relations between employers, workers and trade unions\\n- Sentences should be coded as \"social\" if they deal with aspects of social and moral life, relationships between social groups, and matters of national and social identity. These include: Policing, crime, punishment and rehabilitation of offenders; Immigration, relations between social groups, discrimination and multiculturalism; The role of the state in regulating the social and moral behavior of individuals\\n\\n## Step-by-step instructions\\n\\nFollow these steps to classify the sentence:\\n\\n1. Carefully read the text of the sentence, paying close attention to details.\\n2. Assess whether the sentence belongs to any of the categories. If not, return \\'neither\\' as your response.\\n3. Classify the sentence with the category it belongs to. Return only the name of the category.\\n\\n## Response format\\n\\nOnly include the selected category in your response and no further text.\\n'}\n",
      "{'role': 'user', 'content': \"Text: '''We will: Ensure equality before the law for lesbians and gay men through our new Human Rights Commission and the Bill of Rights.'''\"}\n",
      "{'role': 'assistant', 'content': 'social'}\n",
      "{'role': 'user', 'content': \"Text: '''State power is checked and opportunities are spread throughout society.'''\"}\n",
      "{'role': 'assistant', 'content': 'economic'}\n",
      "{'role': 'user', 'content': \"Text: '''In the 40 years since 1945, more than 10 million people have died in wars around the globe.'''\"}\n",
      "{'role': 'assistant', 'content': 'neither'}\n",
      "{'role': 'user', 'content': \"Text: '''A Capital-Owning Democracy. Share Ownership. Home-ownership leads naturally to other forms of financial provision for the future - notably to pensions and share-ownership.'''\"}\n",
      "{'role': 'assistant', 'content': 'economic'}\n",
      "{'role': 'user', 'content': \"Text: '''Those who commit serious crimes can now expect much tougher punishment.'''\"}\n",
      "{'role': 'assistant', 'content': 'social'}\n",
      "{'role': 'user', 'content': \"Text: '''These improvements will be paid for in part from increasing public expenditure by a net &lt;U+00A3&gt;1.75 billion by the second year.'''\"}\n",
      "{'role': 'assistant', 'content': 'economic'}\n",
      "{'role': 'user', 'content': \"Text: '''We stand up vigorously for Britain's interests abroad.'''\"}\n",
      "{'role': 'assistant', 'content': 'neither'}\n",
      "{'role': 'user', 'content': \"Text: '''Founded in Strength. The ability to act internationally does not come without effort.'''\"}\n",
      "{'role': 'assistant', 'content': 'neither'}\n",
      "{'role': 'user', 'content': \"Text: '''Building on Strength. We will continue to put a high priority on the fight against crime, so that the citizen can feel safe on the street or in his home.'''\"}\n",
      "{'role': 'assistant', 'content': 'social'}\n",
      "{'role': 'user', 'content': \"Text: '''And that Labour's much-vaunted pay pact with the unions collapsed in the industrial anarchy of the winter of discontent, n which the dead went unburied, rubbish piled up in the streets and the country was gripped by a creeping paralysis which Labour was powerless to cure?'''\"}\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    # system prompt\n",
    "    {\"role\": \"system\", \"content\": instructions},\n",
    "    # NOTE: here we inject the few-shot examples between the instruction and the to-be-classified text\n",
    "    *exemplar_messages,\n",
    "    # user input\n",
    "    {\"role\": \"user\", \"content\": text_template.format(text=text)},\n",
    "]\n",
    "print(*messages, sep=\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73093be7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'economic'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=messages,\n",
    "    temperature=0.001,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6596973d",
   "metadata": {},
   "source": [
    "### Iterate over multiple examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5373b62c",
   "metadata": {},
   "source": [
    "Let's first define a custom function to classify texts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7fb21f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_text(text, system_message, exemplars, model):\n",
    "\n",
    "  # clean the text \n",
    "  text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "  # construct input\n",
    "\n",
    "  messages = [\n",
    "    # system prompt\n",
    "    {\"role\": \"system\", \"content\": system_message},\n",
    "    # NOTE: here we inject the few-shot examples between the instruction and the to-be-classified text\n",
    "    *exemplars,\n",
    "    # user input\n",
    "    {\"role\": \"user\", \"content\": text_template.format(text=text)},\n",
    "  ]\n",
    "\n",
    "  response = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=messages,\n",
    "    temperature=0.001,\n",
    "    seed=42\n",
    "  )\n",
    "  \n",
    "  result = response.choices[0].message.content\n",
    "  \n",
    "  return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6788aed",
   "metadata": {},
   "source": [
    "Now we can iterate over example texts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6bee84cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8f64bde9ca04ad78f564bc2fc14d0d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifications_gpt4o = [\n",
    "    classify_text(text, instructions, exemplar_messages, model=MODEL)\n",
    "    for text in tqdm(texts)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dc6a2191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    economic       1.00      0.90      0.95        20\n",
      "     neither       1.00      0.80      0.89        20\n",
      "      social       0.77      1.00      0.87        20\n",
      "\n",
      "    accuracy                           0.90        60\n",
      "   macro avg       0.92      0.90      0.90        60\n",
      "weighted avg       0.92      0.90      0.90        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cr = classification_report(\n",
    "    y_true=inputs.label,\n",
    "    y_pred=classifications_gpt4o,\n",
    ")\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7771ec7e",
   "metadata": {},
   "source": [
    "Without exemplars (few-shot inference), the macro F1 was 0.93.\n",
    "This was already very strong. \n",
    "\n",
    "So in this case, adding exemplars doesn't achieve and improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bd7288",
   "metadata": {},
   "source": [
    "## With Hugging Face _Inference Providers_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de141bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from huggingface_hub import InferenceClient\n",
    "\n",
    "MODEL = \"meta-llama/Meta-Llama-3-70B-Instruct\"\n",
    "client = InferenceClient(MODEL, token=os.environ.get(\"HF_TOKEN\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cc7e19",
   "metadata": {},
   "source": [
    "the **cool thing** is that the `InferenceClient` works exactly like the `openai.Client` class.\n",
    "So the code from above really _doesn't change_!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9161708",
   "metadata": {},
   "source": [
    "#### illustration with a _single_ sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227681fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df.text.iloc[5]\n",
    "print(text)\n",
    "\n",
    "messages = [\n",
    "    # system prompt\n",
    "    {\"role\": \"system\", \"content\": instructions},\n",
    "    # NOTE: here we inject the few-shot examples between the instruction and the to-be-classified text\n",
    "    *exemplar_messages,\n",
    "    # user input\n",
    "    {\"role\": \"user\", \"content\": text_template.format(text=text)},\n",
    "]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=messages,\n",
    "    temperature=0.001,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b9781c",
   "metadata": {},
   "source": [
    "### Iterate over multiple examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c385588",
   "metadata": {},
   "source": [
    "Let's first define a custom function to classify texts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d50b02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_text(text, system_message, exemplars, model):\n",
    "  # NOTE: `model` actually not needed because we setup the InferenceClient with the model already\n",
    "\n",
    "  # clean the text \n",
    "  text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "  # construct input\n",
    "\n",
    "  messages = [\n",
    "    # system prompt\n",
    "    {\"role\": \"system\", \"content\": system_message},\n",
    "    # NOTE: here we inject the few-shot examples between the instruction and the to-be-classified text\n",
    "    *exemplars,\n",
    "    # user input\n",
    "    {\"role\": \"user\", \"content\": text_template.format(text=text)},\n",
    "  ]\n",
    "\n",
    "  response = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=messages,\n",
    "    temperature=0.001,\n",
    "    seed=42\n",
    "  )\n",
    "  \n",
    "  result = response.choices[0].message.content\n",
    "  \n",
    "  return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c57f5a",
   "metadata": {},
   "source": [
    "Now we can iterate over example texts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cff31c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifications_llama3_70b = [\n",
    "    classify_text(text, instructions, exemplar_messages, model=MODEL)\n",
    "    for text in tqdm(texts)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47463ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cr = classification_report(\n",
    "    y_true=inputs.label,\n",
    "    y_pred=classifications_llama3_70b,\n",
    ")\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e8cf96",
   "metadata": {},
   "source": [
    "With few-shot inference, the macro F1 was 0.83.\n",
    "So in this case, we could boost it to 0.89.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc725fc7",
   "metadata": {},
   "source": [
    "Let's try also with the R1 model from DeepSeek:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8996dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL= \"deepseek-ai/DeepSeek-V3-0324\"\n",
    "\n",
    "client = InferenceClient(MODEL, provider=\"sambanova\", token=os.environ.get(\"HF_TOKEN\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7833e949",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifications_deepseekR1 = [\n",
    "    classify_text(text, instructions, exemplar_messages, model=MODEL)\n",
    "    for text in tqdm(texts)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47cb2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "cr = classification_report(\n",
    "    y_true=inputs.label,\n",
    "    y_pred=classifications_deepseekR1,\n",
    ")\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7563c5c6",
   "metadata": {},
   "source": [
    "Here we boost the macro F1 from 0.85 (zero-shot) to 0.90 (9-shot)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6845ec56",
   "metadata": {},
   "source": [
    "## With Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e180bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama import Client\n",
    "client = Client()\n",
    "MODEL = 'gemma3:4b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d16d5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list models\n",
    "available_models = [m['model'] for m in client.list()['models']]\n",
    "\n",
    "if MODEL not in available_models:\n",
    "    import ollama\n",
    "    ollama.pull(MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f385a9d",
   "metadata": {},
   "source": [
    "### Iterate over multiple examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bdacff",
   "metadata": {},
   "source": [
    "Let's first define a custom function to classify tweets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a1a42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_text(text, system_message, exemplars, model):\n",
    "\n",
    "  # clean the text \n",
    "  text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "  # construct input\n",
    "\n",
    "  messages = [\n",
    "    # system prompt\n",
    "    {\"role\": \"system\", \"content\": system_message},\n",
    "    # NOTE: here we inject the few-shot examples between the instruction and the to-be-classified text\n",
    "    *exemplars,\n",
    "    # user input\n",
    "    {\"role\": \"user\", \"content\": text_template.format(text=text)},\n",
    "  ]\n",
    "\n",
    "  # set some options controlling generation behavior\n",
    "  # NOTE: this changed slightly compared to using `openai` Client\n",
    "  opts = {\n",
    "      'seed': 42,         # seed controlling random number generation and thus stochastic generation\n",
    "      'temperature': 0.0, # hyper parameter controlling \"craetivity\", see https://learnprompting.org/docs/basics/configuration_hyperparameters\n",
    "      'max_tokens': 3     # maximum numbers of tokens to generate in completion\n",
    "  }\n",
    "  # NOTE: this changed slightly compared to using `openai` Client\n",
    "  response = client.chat(\n",
    "    model=model,\n",
    "    messages=messages,\n",
    "    options=opts\n",
    "  )\n",
    "  \n",
    "  # NOTE: this changed slightly compared to using `openai` Client\n",
    "  result = response.message.content.strip()\n",
    "  \n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9b3425",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifications_gemma3_4b = [\n",
    "    classify_text(text, instructions, exemplar_messages, model=MODEL)\n",
    "    for text in tqdm(texts)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69172cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cr = classification_report(\n",
    "    y_true=inputs.label,\n",
    "    y_pred=classifications_gemma3_4b,\n",
    ")\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8d6b94",
   "metadata": {},
   "source": [
    "Here we boost the macro F1 from 0.80 to 0.87 (by 8.75%).\n",
    "So for the smallest model, we get the strongest relative gain from using few-shot exemplars."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ce8207",
   "metadata": {},
   "source": [
    "## Similarity-based exemplar selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53aca245",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "embedder = SentenceTransformer('all-mpnet-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526ae157",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_exemplars_by_similarity(text, embeddings, labels, k=3):\n",
    "    \"\"\"\n",
    "    Select the top-k most similar exemplars for each class based on cosine similarity.\n",
    "    \"\"\"\n",
    "    # embed the input text\n",
    "    text_embedding = embedder.encode(text)\n",
    "    # compute cosine similarities\n",
    "    similarities = cosine_similarity([text_embedding], embeddings)[0]\n",
    "    # put similarities and labels in a DataFrame\n",
    "    out = pd.Series(similarities).to_frame('similarity')\n",
    "    out['label'] = labels\n",
    "    # select top-k exemplars per class\n",
    "    out = out.groupby('label')['similarity'].apply(lambda x: x.nlargest(k)).reset_index(level=0, drop=True)\n",
    "    # reshuffle\n",
    "    out = out.sample(frac=1.0, random_state=42)\n",
    "    # return the indices of the selected exemplars\n",
    "    return out.index.tolist()\n",
    "\n",
    "# pre-compute embeddings for all available exemplars (i.e., those not in the set of input texts to classify)\n",
    "exemplars = df[~df.uid.isin(inputs.uid)].reset_index(drop=True)\n",
    "exemplar_embeddings = embedder.encode(exemplars.text.to_list())\n",
    "\n",
    "n_exemplars = 3\n",
    "exemplars_by_text = []\n",
    "# iterate over all texts to select the most similar exemplars for each text\n",
    "for text in tqdm(texts, desc=\"Selecting exemplars by similarity\"):\n",
    "    idxs = select_exemplars_by_similarity(text, exemplar_embeddings, exemplars.label, k=n_exemplars)\n",
    "    exs = exemplars.iloc[idxs]\n",
    "    exemplars_by_text.append(get_exemplar_messages(exs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c5bd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classify all texts using similarity-based exemplar selection\n",
    "classifications_gemma3_4b_sim = []\n",
    "for text, exs in tqdm(zip(texts, exemplars_by_text), total=len(texts)):\n",
    "    pred = classify_text(text, instructions, exs, model=MODEL)\n",
    "    classifications_gemma3_4b_sim.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75742d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cr = classification_report(\n",
    "    y_true=inputs.label,\n",
    "    y_pred=classifications_gemma3_4b_sim,\n",
    ")\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d1ea5a",
   "metadata": {},
   "source": [
    "The macro F1 doesn't change but the performance across label classes becomes more balanced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac8da61",
   "metadata": {},
   "source": [
    "## Inter-LLM agreement?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf9289c",
   "metadata": {},
   "source": [
    "What if we consider the different LLM's classifications as annotations?\n",
    "Then we compute see the degree of their inter-annotator agreement (ICA).\n",
    "\n",
    "This is equivalent to what we did in the [notebook](../annotation/compute_ica_pledge_classification.ipynb) on computing ICA in our policy pledge codings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d27bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from krippendorff import alpha\n",
    "\n",
    "tmp = pd.DataFrame({\n",
    "    'gpt4o': classifications_gpt4o,\n",
    "    'gemma3_4b': classifications_gemma3_4b,\n",
    "    'llama3_70b': classifications_llama3_70b,\n",
    "    'deepseekR1': classifications_deepseekR1,\n",
    "})\n",
    "\n",
    "label2id = {\n",
    "    'economic': 0,\n",
    "    'social': 1,\n",
    "    'neither': 2,\n",
    "}\n",
    "\n",
    "tmp = tmp.apply(lambda x: x.map(label2id))\n",
    "alpha(tmp.T.values, level_of_measurement='nominal')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22dcec6e",
   "metadata": {},
   "source": [
    "😳 This is a very strong agreement and about 10% higher than the agreemet between LLMs' zero-shot classifications."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "advanced_text_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
