{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "025017f5",
   "metadata": {},
   "source": [
    "# Few-shot text classification with Llama 3.1 8B and ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676afdc0",
   "metadata": {},
   "source": [
    "For **running on _Google Colab_**, see notebook [llm_zeroshot_classification_ollama.ipynb](./llm_zeroshot_classification_ollama.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da313a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from ollama import Client\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd88ae14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the ollama client that communicates with the `ollama` server running in the background\n",
    "client = Client()\n",
    "MODEL = 'llama3.1:8b' # currently the latest version of GPT-4o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44927e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_available_models = lambda : [m['model'] for m in client.list()['models']]\n",
    "\n",
    "if MODEL not in get_available_models():\n",
    "  print(f\"Model not found. Running `client.pull('{MODEL}')` to download it.\")\n",
    "  client.pull(MODEL)\n",
    "\n",
    "# confirm\n",
    "assert MODEL in get_available_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d32c73c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join('..', 'data', 'labeled', 'benoit_crowdsourced_2016', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33c6f01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED=42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e11918",
   "metadata": {},
   "source": [
    "## Define the task\n",
    "\n",
    "In this example, we adapt the instruction for the economic/social/neither policy area classification task in Benoit et al. (2016)\n",
    "\n",
    "- see [this README file](../data/labeled/benoit_crowdsourced_2016/README.md) for a description of the data and tasks covered in the paper\n",
    "- see [this file](../data/labeled/benoit_crowdsourced_2016/instructions/econ_social_policy.md) for a copy of their original task instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86c19a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"\"\"\n",
    "This task involves reading sentences from political texts and judging whether these deal with economic or social policy.\n",
    "\n",
    "The sentences you will be asked to interpret come from political party manifestos.\n",
    "Some of these sentences will deal with economic policy; some will deal with social policy; other sentences will deal with neither economic nor social policy. We tell you below about what we mean by \"economic\" and \"social\" policy.\n",
    "\n",
    "First, you will read a short section from a party manifesto.\n",
    "For the sentence highlighted in red, enter your best judgment about whether it mainly refers to economic policy, to social policy, or to neither.\n",
    "\n",
    "If the sentence refers to economic policy, select \"economic\" in the drop down menu; if it refers to social policy, select \"social\".\n",
    "If the sentence does not refer to either policy area, select \"Not Economic or Social\" -- in this case you will move directly to the next sentence.\n",
    "\n",
    "Now we need to tell you about what we mean by \"economic\" and \"social\" policy.\n",
    "\n",
    "## What is \"economic\" policy?\n",
    "\n",
    "**\"Economic\" policies** deal with all aspects of the economy, including:\n",
    "\n",
    "- Taxation\n",
    "- Government spending\n",
    "- Services provided by the government or other public bodies\n",
    "- Pensions, unemployment and welfare benefits, and other state benefits\n",
    "- Property, investment and share ownership, public or private\n",
    "- Interest rates and exchange rates\n",
    "- Regulation of economic activity, public or private\n",
    "- Relations between employers, workers and trade unions\n",
    "\n",
    "## What is \"social\" policy?\n",
    "\n",
    "**\"Social\" policies** deal with aspects of social and moral life, relationships between social groups, and matters of national and social identity, including:\n",
    "\n",
    "- Policing, crime, punishment and rehabilitation of offenders;\n",
    "- Immigration, relations between social groups, discrimination and multiculturalism;\n",
    "- The role of the state in regulating the social and moral behavior of individuals\n",
    "\n",
    "## Your task\n",
    "\n",
    "Classify the input text in one of the following categories: economic, social, neither\n",
    "\n",
    "## Response format\n",
    "\n",
    "Only respond with the chosen category and no additional text or explanations \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092f2b49",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d65075f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.io import read_tabular\n",
    "from utils.finetuning import split_data\n",
    "\n",
    "fp = data_path+'benoit_crowdsourced_2016-policy_area.csv'\n",
    "df = read_tabular(fp, columns=['text', 'label'])\n",
    "\n",
    "id2label = {\n",
    "    2: \"economic\",\n",
    "    3: \"social\",\n",
    "    1: \"neither\"\n",
    "}\n",
    "\n",
    "df.label = df.label.map(id2label)\n",
    "\n",
    "# subset to 100 examples per label class \n",
    "df = df.groupby('label').sample(n=100, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1093ce27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "economic    100\n",
       "neither     100\n",
       "social      100\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "765f7c93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['train', 'test'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split into \"training\" and \"test\" data\n",
    "#  - training is used for examples\n",
    "#  - test is used for few-shot classification  \n",
    "# note: if you had different example selection \n",
    "#  strategies of variations of a prompt, you could use a dev for comparing them\n",
    "data_splits = split_data(df, test_size=0.5, dev_size=None, stratify_by='label', return_dict=True)\n",
    "data_splits.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9773717a",
   "metadata": {},
   "source": [
    "## sample examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca568f2d",
   "metadata": {},
   "source": [
    "There is various different ways of sampling few-shot exemplars\n",
    "\n",
    "Here, we take the **most representative exemplars** by \n",
    "\n",
    "1. embedding exemplars\n",
    "2. computing the centroid for each label class\n",
    "3. and ranking exemplars in terms of their closeness to their class centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a19c448b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m\n",
      "\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mAnyStr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtruncate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0moptions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mollama\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOptions\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mkeep_alive\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mMapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m <no docstring>\n",
      "\u001b[0;31mFile:\u001b[0m      ~/miniforge3/envs/advanced_text_analysis_gesis_2024/lib/python3.11/site-packages/ollama/_client.py\n",
      "\u001b[0;31mType:\u001b[0m      method"
     ]
    }
   ],
   "source": [
    "client.embed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9cc8055",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import List\n",
    "def embed(texts: List[str]):\n",
    "    # see https://platform.openai.com/docs/guides/embeddings/what-are-embeddings?lang=python\n",
    "    texts = [text.replace(\"\\n\", \" \") for text in texts] \n",
    "    res = client.embed(\n",
    "        input=texts,\n",
    "        model=MODEL\n",
    "        # alternatively, take 'mxbai-embed-large' for faster embedding\n",
    "    )\n",
    "    return np.array(res['embeddings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ec6fb99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c247dceda2c4306884f5324a13eb34e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "ranked_exemplars = {}\n",
    "for label_class, df in tqdm(data_splits['train'].groupby('label')):\n",
    "    # get embeddings from OpenAI model\n",
    "    embeddings = embed(df.text.to_list())\n",
    "    # compute centroid\n",
    "    centroid = embeddings.mean(axis=0)\n",
    "    # compute cosine similarity between the centroid and the embeddings\n",
    "    dists = cosine_similarity([centroid], embeddings)\n",
    "    # rank the examples by similarity, descending\n",
    "    ranked_indices = np.argsort(dists[0])[::-1]\n",
    "    # add to output\n",
    "    ranked_exemplars[label_class]= df.iloc[ranked_indices, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a45eeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def get_n_examples(ranked_exemplars, k, shuffle=True, random_state=SEED):\n",
    "    exs = []\n",
    "    for label_class, exemplars in ranked_exemplars.items():\n",
    "        ex = exemplars[:k].to_list()\n",
    "        ex = [{'text': text, 'label': label_class} for text in ex]\n",
    "        exs.extend(ex)\n",
    "    if shuffle:\n",
    "        random.Random(random_state).shuffle(exs)\n",
    "    return exs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a9d4d18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'Liberal Democrats are determined that Britain should lead this reform.',\n",
       "  'label': 'neither'},\n",
       " {'text': 'We support police initiatives to target the hard core of persistent criminals.',\n",
       "  'label': 'social'},\n",
       " {'text': 'Labour will be a friend of those denied human rights and a supporter of steps to strengthen them.',\n",
       "  'label': 'social'},\n",
       " {'text': 'We will focus more on the poorest, paying particular attention to development within the Commonwealth.',\n",
       "  'label': 'neither'},\n",
       " {'text': 'Racial discrimination is an injustice and can have no place in a tolerant and civilised society.',\n",
       "  'label': 'social'},\n",
       " {'text': 'The programme which can be quickly and easily established will allow us to start bringing down unemployment immediately.',\n",
       "  'label': 'economic'},\n",
       " {'text': 'We will bring in much tighter labelling requirements for all foods, and make funding available for food research and scientific establishments.',\n",
       "  'label': 'neither'},\n",
       " {'text': 'It is in sharp contrast to the Tory goal of abolishing capital gains and inheritance tax, at least half the benefit of which will go to the richest 5,000 families in the country.',\n",
       "  'label': 'economic'},\n",
       " {'text': 'But we will go further in helping older pensioners, who tend to be poorer.',\n",
       "  'label': 'economic'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_n_examples(ranked_exemplars, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "465f900d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_exemplars_list_to_convo(exemplars):\n",
    "    convo = []\n",
    "    for ex in exemplars:\n",
    "        convo.append({\"role\": \"user\", \"content\": f\"'''{ex['text']}'''\"},)\n",
    "        convo.append({\"role\": \"assistant\", \"content\": ex['label']},)\n",
    "    return convo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35819e24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': \"'''Liberal Democrats are determined that Britain should lead this reform.'''\"},\n",
       " {'role': 'assistant', 'content': 'neither'},\n",
       " {'role': 'user',\n",
       "  'content': \"'''We support police initiatives to target the hard core of persistent criminals.'''\"},\n",
       " {'role': 'assistant', 'content': 'social'},\n",
       " {'role': 'user',\n",
       "  'content': \"'''Labour will be a friend of those denied human rights and a supporter of steps to strengthen them.'''\"},\n",
       " {'role': 'assistant', 'content': 'social'}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_exemplars_list_to_convo(get_n_examples(ranked_exemplars, 3))[:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7520f9",
   "metadata": {},
   "source": [
    "### A single text example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed4861eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_input = data_splits['test'].text.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "647308d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to conversation history\n",
    "messages = [\n",
    "  # system prompt\n",
    "  {\"role\": \"system\", \"content\": instructions},\n",
    "  # exemplars\n",
    "  *convert_exemplars_list_to_convo(get_n_examples(ranked_exemplars, 3))[:6],\n",
    "  # user input\n",
    "  {\"role\": \"user\", \"content\": f\"'''{text_input}'''\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f2189ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = options = {'seed': 42, 'temperature': 0.0, 'max_tokens': 3}\n",
    "response = client.chat(\n",
    "  model=MODEL,\n",
    "  messages=messages,\n",
    "  options=options\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c6cc4b18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant', 'content': 'neither'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parse the response\n",
    "response['message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7709d230",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neither'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_splits['test'].label.values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6596973d",
   "metadata": {},
   "source": [
    "### Iterate over multiple examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5373b62c",
   "metadata": {},
   "source": [
    "Let's first define a custom function to classify tweets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7fb21f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "def classify_tweet(text, model: str, system_message: str, exemplars: List[Dict]):\n",
    "\n",
    "  # clean the text \n",
    "  text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "  # construct input\n",
    "\n",
    "  messages = [\n",
    "    # system prompt\n",
    "    {\"role\": \"system\", \"content\": system_message},\n",
    "    # exemplars\n",
    "    *convert_exemplars_list_to_convo(exemplars),\n",
    "    # user input\n",
    "    {\"role\": \"user\", \"content\": f\"'''{text}'''\"},\n",
    "  ]\n",
    "\n",
    "  options = options = {'seed': 42, 'temperature': 0.0, 'max_tokens': 3}\n",
    "  response = client.chat(\n",
    "    model=MODEL,\n",
    "    messages=messages,\n",
    "    options=options\n",
    "  )\n",
    "  \n",
    "  if 'message' not in response:\n",
    "      print(\"WARNING: Response should have one 'meassage'\")\n",
    "      return None\n",
    "  if not response['done'] or response['done_reason'] != 'stop':\n",
    "      print(\"WARNING: Response should have 'done_reason' of 'stop' but got:\", response['done_reason'])\n",
    "      return None\n",
    "\n",
    "  return response['message']['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6788aed",
   "metadata": {},
   "source": [
    "Now we can iterate over example texts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "22799dc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f43c1823941c418385f0859ffb339096",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "texts = data_splits['test'].text.to_list()\n",
    "exemplars = get_n_examples(ranked_exemplars, 3)\n",
    "classifications = [classify_tweet(text, model=MODEL, system_message=instructions, exemplars=exemplars) for text in tqdm(texts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6d2c02f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    economic       0.89      0.62      0.73        50\n",
      "     neither       0.67      0.82      0.74        50\n",
      "      social       0.70      0.76      0.73        50\n",
      "\n",
      "    accuracy                           0.73       150\n",
      "   macro avg       0.75      0.73      0.73       150\n",
      "weighted avg       0.75      0.73      0.73       150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "cr = classification_report(\n",
    "    y_true = data_splits['test'].label.to_list(),\n",
    "    y_pred = classifications\n",
    ")\n",
    "\n",
    "print(cr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_text_annotation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
